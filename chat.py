# import streamlit as st
# import openai

# def show(navigate):
#     # Configura√ß√£o da chave da API da OpenAI
#     openai.api_key = "key"

#     # Estilos personalizados com CSS para cores e design do layout
#     st.markdown("""
#         <style>
#         /* Ajustes para o layout */
#         .reportview-container {
#             width: 90%; 
#             max-width: 1400px; 
#             margin: auto; 
#         }
#         .main {
#             background-color: #FFFFFF;
#             padding: 5px;
#         }
#         /* Estilo do t√≠tulo */
#         h1 {
#             font-size: 36px;
#             color: #0D47A1;
#             margin-top: -50px;
#         }
#         /* Fundo da mensagem do usu√°rio */
#         .st-chat-message-user {
#             background-color: #DCEFFD;
#             color: #333;
#             padding: 10px;
#             border-radius: 8px;
#             text-align: left;
#         }
#         /* Fundo da mensagem do assistente */
#         .st-chat-message-assistant {
#             background-color: #E5F7E7;
#             color: #333;
#             padding: 10px;
#             border-radius: 8px;
#             text-align: left;
#         }
#         </style>
#     """, unsafe_allow_html=True)

#     # T√≠tulo da Aplica√ß√£o
#     st.title("Health Analyzer")

#     # Recuperar dados da p√°gina anterior
#     nome_paciente = st.session_state.get("paciente", "Paciente")
#     queixas = st.session_state.get("queixas", "Nenhuma queixa registrada.")
#     peso = st.session_state.get("peso", "informa√ß√£o n√£o registrada")
#     altura = st.session_state.get("altura", "informa√ß√£o n√£o registrada")
#     pressao_s = st.session_state.get("pressao_s", "informa√ß√£o n√£o registrada")
#     pressa_d = st.session_state.get("pressao_d", "informa√ß√£o n√£o registrada")
#     pressao_dif = st.session_state.get("pressao_dif", "informa√ß√£o n√£o registrada")
#     temperatura = st.session_state.get("temperatura", "informa√ß√£o n√£o registrada")
#     oxigenacao = st.session_state.get("oxigenacao", "informa√ß√£o n√£o registrada")
#     comorbidade = st.session_state.get("comorbidade","informa√ß√£o n√£o registrada")

#     # Inicializar vari√°veis de estado da sess√£o
#     if "openai_model" not in st.session_state:
#         st.session_state["openai_model"] = "gpt-4o-mini"

#     if "messages" not in st.session_state:
#         st.session_state.messages = []
#         prompt_inicial = (
#             f"Voc√™ √© um assistente m√©dico virtual. O paciente {nome_paciente} tem as seguintes medidas peso:{peso}, altura:{altura},\
#             temperatura:{temperatura}, oxigena√ß√£o{oxigenacao}, press√£o arterial sist√≥lica {pressao_s}, press√£o arterial diast√≥lica: {pressa_d},\
#             press√£o arterial diferencial: {pressao_dif} comorbidade: {comorbidade}, e  relatou os seguintes sintomas: {queixas}. "\
#             "Com base nisso, indique o m√©dico especialista que o paciente deve procurar e forne√ßa\
#             uma recomenda√ß√£o inicial clara e simples sobre a√ß√µes que o paciente deve tomar."
#         )
#         # prompt_inicial = (
#         #     f"Voc√™ √© um assistente m√©dico virtual. O paciente {nome_paciente} com base nos dados da triagem tem as seguintes medidas peso:{peso}, altura:{altura},\
#         #     temperatura:{temperatura}, oxigena√ß√£o{oxigenacao}, press√£o arterial sist√≥lica {pressao_s}, press√£o arterial diast√≥lica: {pressa_d},\
#         #     press√£o arterial diferencial: {pressao_dif} comorbidade: {comorbidade}, e  relatou os seguintes sintomas: {queixas}. "\
#         #     "Com base nisso, indique o m√©dico especialista mais adquado para atender o paciente e forne√ßa para o m√©dico um resumo\
#         #     do quadro do paciente para que ele possa se preparar para "
#         # )

#         response = openai.ChatCompletion.create(
#             model=st.session_state["openai_model"],
#             messages=[{"role": "system", "content": prompt_inicial}]
#         )["choices"][0]["message"]["content"]

#         # Adicionar a resposta inicial ao hist√≥rico
#         st.session_state.messages.append({"role": "assistant", "content": response})

#     # Exibir mensagens anteriores do chat com avatares personalizados
#     for message in st.session_state.messages:
#         avatar = "üë§" if message["role"] == "user" else "ü©∫"  # √çcone de avatar para usu√°rio e assistente
#         with st.chat_message(message["role"], avatar=avatar):
#             st.markdown(message["content"])

#     # Entrada do usu√°rio no chat
#     if prompt := st.chat_input("Deseja compartilhar mais detalhes ou outros sintomas?"):
#         st.session_state.messages.append({"role": "user", "content": prompt})
#         with st.chat_message("user", avatar="üë§"):
#             st.markdown(prompt)

#         # Preparar o prompt para o modelo
#         mensagem_do_modelo = (
#             f"Paciente: {nome_paciente}, "
#             f"Queixas iniciais: {queixas}. "
#             f"Peso: {peso}. "
#             f"Altura: {altura}. "
#             f"Oxigenacao: {oxigenacao}. "
#             f"Temperatura: {temperatura}. "
#             f"Press√£o Arterial Diast√≥lica: {pressa_d}. "
#             f"Press√£o Arterial Sist√≥lica: {pressao_s}. "
#             f"Press√£o Arterial Diferencial: {pressao_dif}. "
#             f"Comorbidade: {comorbidade}. "
#             f"Informa√ß√µes adicionais: {prompt}. "
#             f"Baseado nisso, qual orienta√ß√£o voc√™ daria?"
#         )
        
#         # Gerar resposta da IA com a informa√ß√£o adicional dos sintomas
#         with st.chat_message("assistant", avatar="ü©∫"):
#             response = ""
#             # Adicione o contexto inicial, se for a primeira intera√ß√£o
#             if len(st.session_state.messages) == 1:  # Apenas a mensagem inicial existe
#                 st.session_state.messages.insert(0, {
#                 "role": "system", 
#                 "content": prompt_inicial
#             })

#         # Gera√ß√£o da resposta com hist√≥rico completo
#             stream = openai.ChatCompletion.create(
#                 model=st.session_state["openai_model"],
#                 messages=st.session_state.messages,  # Envia o hist√≥rico completo
#                 stream=True,
#             )

            
#             # Coletar o conte√∫do da resposta de forma incremental
#             for chunk in stream:
#                 content = chunk.choices[0].delta.get("content", "")
#                 response += content

#             # Exibir a resposta completa da IA
#             st.markdown(response)

#         # Adicionar a resposta ao hist√≥rico de mensagens
#         st.session_state.messages.append({"role": "assistant", "content": response})

import streamlit as st
import openai

def show(navigate):
    # Configura√ß√£o da chave da API da OpenAI
    openai.api_key = "sk-rUSqK2zQX7STu1sWSPOq01zpo63VD8we9ooEc2SYAjT3BlbkFJVzrrxq_tfSn9jCL4Drh0eZuNpepNij5vD9si5gjBwA"

    # Estilos personalizados com CSS para cores e design do layout
    st.markdown("""
        <style>
        /* Ajustes para o layout */
        .reportview-container {
            width: 90%; 
            max-width: 1400px; 
            margin: auto; 
        }
        .main {
            background-color: #FFFFFF;
            padding: 5px;
        }
        /* Estilo do t√≠tulo */
        h1 {
            font-size: 36px;
            color: #0D47A1;
            margin-top: -50px;
        }
        /* Fundo da mensagem do usu√°rio */
        .st-chat-message-user {
            background-color: #DCEFFD;
            color: #333;
            padding: 10px;
            border-radius: 8px;
            text-align: left;
        }
        /* Fundo da mensagem do assistente */
        .st-chat-message-assistant {
            background-color: #E5F7E7;
            color: #333;
            padding: 10px;
            border-radius: 8px;
            text-align: left;
        }
        </style>
    """, unsafe_allow_html=True)

    # T√≠tulo da Aplica√ß√£o
    st.title("Health Analyzer")

    # Recuperar dados da p√°gina anterior
    nome_paciente = st.session_state.get("paciente", "Paciente")
    queixas = st.session_state.get("queixas", "Nenhuma queixa registrada.")
    peso = st.session_state.get("peso", "informa√ß√£o n√£o registrada")
    altura = st.session_state.get("altura", "informa√ß√£o n√£o registrada")
    pressao_s = st.session_state.get("pressao_s", "informa√ß√£o n√£o registrada")
    pressa_d = st.session_state.get("pressao_d", "informa√ß√£o n√£o registrada")
    pressao_dif = st.session_state.get("pressao_dif", "informa√ß√£o n√£o registrada")
    temperatura = st.session_state.get("temperatura", "informa√ß√£o n√£o registrada")
    oxigenacao = st.session_state.get("oxigenacao", "informa√ß√£o n√£o registrada")
    comorbidade = st.session_state.get("comorbidade","informa√ß√£o n√£o registrada")

    # Inicializar vari√°veis de estado da sess√£o
    if "openai_model" not in st.session_state:
        st.session_state["openai_model"] = "gpt-4"

    if "messages" not in st.session_state:
        st.session_state.messages = []
        
        # Adicionar mensagem inicial com recomenda√ß√£o baseada nas queixas
        # prompt_inicial = (
        #     f"Voc√™ √© um assistente m√©dico virtual. O paciente {nome_paciente} relatou os seguintes sintomas: {queixas}. "
        #     "Com base nisso, forne√ßa uma recomenda√ß√£o inicial clara e simples sobre o qual o paciente deve fazer e indique um m√©dico especialista em que o paciente deve procurar."
        # )
        prompt_inicial = (
            f"Voc√™ √© um assistente m√©dico virtual. O paciente {nome_paciente} tem as seguintes medidas peso:{peso}, altura:{altura},\
            temperatura:{temperatura}, oxigena√ß√£o{oxigenacao}, press√£o arterial sist√≥lica {pressao_s}, press√£o arterial diast√≥lica: {pressa_d},\
            press√£o arterial diferencial: {pressao_dif} comorbidade: {comorbidade}, e  relatou os seguintes sintomas: {queixas}. "\
            "Com base nas informa√ß√µes vindas da triagem, incialmente cumprimente o paciente e d√™ um panorama (de forma bem resumida) acerca da gravidade do quadro, em seguida fale que ele logo ser√° atendido e pergunte se h√° algo que precisa complementar"
        )
        response = openai.ChatCompletion.create(
            model=st.session_state["openai_model"],
            messages=[{"role": "system", "content": prompt_inicial}]
        )["choices"][0]["message"]["content"]

        # Adicionar a resposta inicial ao hist√≥rico
        st.session_state.messages.append({"role": "assistant", "content": response})

    # Exibir mensagens anteriores do chat com avatares personalizados
    for message in st.session_state.messages:
        avatar = "üë§" if message["role"] == "user" else "ü©∫"  # √çcone de avatar para usu√°rio e assistente
        with st.chat_message(message["role"], avatar=avatar):
            st.markdown(message["content"])

    # Entrada do usu√°rio no chat
    if prompt := st.chat_input("Deseja compartilhar mais detalhes ou outros sintomas?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üë§"):
            st.markdown(prompt)

        # Preparar o prompt para o modelo
        mensagem_do_modelo = (
            f"Paciente: {nome_paciente}, "
            f"Queixas iniciais: {queixas}. "
            f"Peso: {peso}. "
            f"Altura: {altura}. "
            f"Oxigenacao: {oxigenacao}. "
            f"Temperatura: {temperatura}. "
            f"Press√£o Arterial Diast√≥lica: {pressa_d}. "
            f"Press√£o Arterial Sist√≥lica: {pressao_s}. "
            f"Press√£o Arterial Diferencial: {pressao_dif}. "
            f"Comorbidade: {comorbidade}. "
            f"Informa√ß√µes adicionais: {prompt}. "
            f"Baseado nisso, qual orienta√ß√£o voc√™ daria?"
        )
        
        # Gerar resposta da IA com a informa√ß√£o adicional dos sintomas
        with st.chat_message("assistant", avatar="ü©∫"):
            response = ""
            stream = openai.ChatCompletion.create(
                model=st.session_state["openai_model"],
                messages=[
                    {"role": "system", "content": "Voc√™ √© um assistente m√©dico virtual que deve fornecer recomenda√ß√µes inciais simples e claras com base nas informa√ß√µes disponibilizadas sobre a condi√ß√£o de sa√∫de do paciente, por √∫ltimo tamb√©m deve recomendar um m√©dido especialista."},
                    {"role": "user", "content": mensagem_do_modelo}
                ],
                stream=True,
            )
            
            # Coletar o conte√∫do da resposta de forma incremental
            for chunk in stream:
                content = chunk.choices[0].delta.get("content", "")
                response += content

            # Exibir a resposta completa da IA
            st.markdown(response)

        # Adicionar a resposta ao hist√≥rico de mensagens
        st.session_state.messages.append({"role": "assistant", "content": response})